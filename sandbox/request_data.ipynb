{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "\n",
    "# NOTE: this script is written in python 3, because python 2 has some SSL issues when threading\n",
    "# concurrent requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# specify you api credentials, begin time and inputs\n",
    "username = 'OOIAPI-9N9UMLHV9W5GOP'\n",
    "token = 'SJN6HXHH116OZ8'\n",
    "begin_time_set = datetime.datetime(2017, 6, 28, 0,0,0)\n",
    "array = 'test2'\n",
    "input_path = '/Users/knuth/Documents/ooi/repos/github/ooi_stats/sandbox/test_input/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up threads pool and execute requests\n",
    "pool = concurrent.futures.ThreadPoolExecutor(max_workers=12)\n",
    "session = requests.session()\n",
    "\n",
    "# set up function to send requests\n",
    "def request_data(url,username,token):\n",
    "    auth = (username, token)\n",
    "    return session.get(url,auth=auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 days of data since 2017-06-28T00:00:00.000Z will be requested for each refdes+stream.\n"
     ]
    }
   ],
   "source": [
    "# base url for the request that will be built using the inputs above.\n",
    "BASE_URL = 'https://ooinet.oceanobservatories.org/api/m2m/12576/sensor/inv/'\n",
    "\n",
    "# request only parameter 7 (time)\n",
    "parameter = '7'\n",
    "\n",
    "# read in csv\n",
    "refdes_streams = input_path + array + '.csv'\n",
    "refdes_streams_df = pd.read_csv(refdes_streams)\n",
    "\n",
    "# prepare time stamp manipulators and range of data requests\n",
    "begin_time_str = begin_time_set.strftime('%Y-%m-%dT%H:%M:%S.000Z')\n",
    "ntp_epoch = datetime.datetime(1900, 1, 1)\n",
    "unix_epoch = datetime.datetime(1970, 1, 1)\n",
    "ntp_delta = (unix_epoch - ntp_epoch).total_seconds()\n",
    "now = datetime.datetime.now()\n",
    "days = abs(begin_time_set.date() - now.date())\n",
    "days = int(days.days)\n",
    "print(days,\"days of data since\", begin_time_str, \"will be requested for each refdes+stream.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building instrument requests...\n"
     ]
    }
   ],
   "source": [
    "# iterate over reference designators, delivery methods and streams in csv to build request urls by refdes.\n",
    "# the urls are stored in a dictonary.\n",
    "\n",
    "print(\"Building instrument requests...\")\n",
    "requests_dict = {}\n",
    "for index, row in refdes_streams_df.iterrows():\n",
    "\n",
    "    # start at the begin time set above\n",
    "    begin_time = begin_time_set\n",
    "    begin_time_str = begin_time.strftime('%Y-%m-%dT%H:%M:%S.000Z')\n",
    "    \n",
    "    #step forward by 1 day (86400 seconds) with each new request\n",
    "    end_time = begin_time + datetime.timedelta(seconds=86400)\n",
    "    end_time_str = end_time.strftime('%Y-%m-%dT%H:%M:%S.000Z')\n",
    "\n",
    "    ref_des =  row['refdes']\n",
    "    sub_site = ref_des[:8]\n",
    "    platform = ref_des[9:14]\n",
    "    instrument = ref_des[15:27]\n",
    "    stream = row['stream']\n",
    "    delivery_method = row['method']\n",
    "    \n",
    "    ref_des_list = []\n",
    "\n",
    "    for i in range(days):\n",
    "        request_url = '/'.join((BASE_URL, sub_site, platform, instrument, delivery_method, stream))\n",
    "        request_url = request_url+'?beginDT='+begin_time_str+'&endDT='+end_time_str+'&limit=1000&parameters='+parameter\n",
    "        \n",
    "        ref_des_list.append(request_url)\n",
    "\n",
    "        begin_time = begin_time + datetime.timedelta(seconds=86400)\n",
    "        begin_time_str = begin_time.strftime('%Y-%m-%dT%H:%M:%S.000Z')\n",
    "        end_time = end_time + datetime.timedelta(seconds=86400)\n",
    "        end_time_str = end_time.strftime('%Y-%m-%dT%H:%M:%S.000Z')\n",
    "        \n",
    "    requests_dict[ref_des] = ref_des_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instrument request urls built. Requesting data for...\n",
      "RS03AXPS-SF03A-3A-FLORTD301\n",
      "2017-07-05\n",
      "2017-06-29\n",
      "2017-07-08\n",
      "2017-06-28\n",
      "2017-07-02\n",
      "2017-07-06\n",
      "2017-07-10\n",
      "2017-07-09\n",
      "2017-06-30\n",
      "2017-07-07\n",
      "2017-07-01\n",
      "2017-07-14\n",
      "2017-07-03\n",
      "2017-07-04\n",
      "2017-07-11\n",
      "2017-07-15\n",
      "2017-07-20\n",
      "2017-07-16\n",
      "2017-07-13\n",
      "2017-07-12\n",
      "2017-07-22\n",
      "2017-07-21\n",
      "2017-07-18\n",
      "2017-07-17\n",
      "2017-07-19\n",
      "2017-07-23\n"
     ]
    }
   ],
   "source": [
    "# request data and store entry for refdes, stream and first data point returned\n",
    "print(\"Instrument request urls built. Requesting data for...\")\n",
    "\n",
    "ref_des_list = []\n",
    "stream_list = []\n",
    "timestamp_list = []\n",
    "\n",
    "\n",
    "for key, values in requests_dict.items():\n",
    "    print(key)\n",
    "    future_to_url = {pool.submit(request_data, url, username, token): url for url in values}\n",
    "    for future in concurrent.futures.as_completed(future_to_url):\n",
    "        url = future_to_url[future]\n",
    "        try:    \n",
    "            data = future.result()\n",
    "            data = data.json()\n",
    "            stream = data[0]['pk']['stream']\n",
    "            timestamp = data[0]['time']\n",
    "            timestamp = datetime.datetime.utcfromtimestamp(timestamp - ntp_delta).replace(microsecond=0)\n",
    "            timestamp = timestamp.date()\n",
    "            print(timestamp)\n",
    "\n",
    "            ref_des_list.append(key)\n",
    "            stream_list.append(stream)\n",
    "            timestamp_list.append(timestamp)\n",
    "            \n",
    "        except:\n",
    "            data = future.result()\n",
    "#             data = data.json()\n",
    "#             print(data['status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert lists to data frame\n",
    "data_dict = {\n",
    "    'refdes':ref_des_list,\n",
    "    'stream':stream_list,\n",
    "    'timestamp':timestamp_list}\n",
    "ooi_data = pd.DataFrame(data_dict, columns = ['refdes', 'stream', 'timestamp'])\n",
    "ooi_data = ooi_data[ooi_data.timestamp >= begin_time_set.date()]\n",
    "ooi_data.to_csv('test_output/'+array+'/data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
